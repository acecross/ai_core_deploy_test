apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: abap-rag-server
  annotations:
    scenarios.ai.sap.com/name: abap-rag
    executables.ai.sap.com/name: rag-fastapi
  labels:
    ai.sap.com/version: "1.0.0"        # required
spec:
  inputs:
    parameters:
      - name: image
        type: string
      - name: port
        type: string
        default: "8080"

  # Entire KServe spec as a single YAML string
  template: |
    apiVersion: serving.kserve.io/v1beta1
    kind: InferenceService
    metadata:
      name: "{{ name }}"
      labels:
        ai.sap.com/resourcePlan: infer.s
    spec:
      predictor:
        # Remove this block if your image is PUBLIC
        imagePullSecrets:
          - name: ghcr
        containers:
          - name: kserve-container            # <- required name
            image: "{{inputs.parameters.image}}"
            ports:
              - containerPort: {{inputs.parameters.port}}
                protocol: TCP                  # <- required protocol
            env:
              - name: PORT
                value: "{{inputs.parameters.port}}"
              - name: LLM_PROVIDER
                value: "aicore"
              - name: LLM_MODEL
                value: "gpt-4o-mini"
            readinessProbe:
              httpGet:
                path: /healthz
                port: {{inputs.parameters.port}}
              initialDelaySeconds: 5
              periodSeconds: 5
            livenessProbe:
              httpGet:
                path: /healthz
                port: {{inputs.parameters.port}}
              initialDelaySeconds: 15
              periodSeconds: 10

  resources:
    minReplicas: 1
    maxReplicas: 2
